{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "864e4469-cd3c-44c8-8dc0-cfcb9c8253d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "# 读取数据\n",
    "with open(\"../xfdata/dataset/job_list.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    job_list = json.load(f)\n",
    "with open(\"../xfdata/dataset/train.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    train = json.load(f)\n",
    "with open(\"../xfdata/dataset/test.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    test = json.load(f)\n",
    "    \n",
    "# 1、教育经历\n",
    "with open(\"../user_data/profileEduExps_sentences.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    profileEduExps_sentences = json.load(f)\n",
    "\n",
    "# 2、社会经历\n",
    "with open(\"../user_data/profileSocialExps_sentences.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    profileSocialExps_sentences = json.load(f)\n",
    "\n",
    "# 3、项目经历\n",
    "with open(\"../user_data/profileProjectExps_sentences.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    profileProjectExps_sentences = json.load(f)\n",
    "\n",
    "# 4、工作经历\n",
    "with open(\"../user_data/profileWorkExps_sentences.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    profileWorkExps_sentences = json.load(f)\n",
    "\n",
    "# 5、技能\n",
    "with open(\"../user_data/profileSkills_sentences.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    profileSkills_sentences = json.load(f)\n",
    "\n",
    "# 6、荣誉\n",
    "with open(\"../user_data/profileAwards_sentences.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    profileAwards_sentences = json.load(f)\n",
    "\n",
    "# 7、求职意愿\n",
    "with open(\"../user_data/profileDesire_sentences.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    profileDesire_sentences = json.load(f)\n",
    "\n",
    "# 8、语言\n",
    "with open(\"../user_data/profileLanguage_sentences.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    profileLanguage_sentences = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dff3db73-6a23-4b49-ad83-a6de7523dce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "# 获取标签\n",
    "labels = [i[\"positionID\"] for i in train]\n",
    "labelencoder = LabelEncoder()\n",
    "labels = labelencoder.fit_transform(labels)\n",
    "print(len(np.unique(labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624c359b-214c-4683-9ce8-c9b9ebd1b068",
   "metadata": {},
   "source": [
    "# 使用BERT进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f59ab48-6cf6-4982-83c8-2e4db819ddb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 6500\n",
      "16000 16000\n",
      "4000 4000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "sentences = []\n",
    "# 调整位置\n",
    "for s1, s2, s3, s4, s5, s6, s7, s8 in zip(profileEduExps_sentences, profileWorkExps_sentences, profileProjectExps_sentences, \\\n",
    "profileSocialExps_sentences, profileSkills_sentences, profileAwards_sentences, profileDesire_sentences, \\\n",
    "profileLanguage_sentences):\n",
    "    sentences.append(s1 + s2 + s3 + s4 + s5 + s6 + s7 + s8)\n",
    "\n",
    "train_sentences, test_sentences = sentences[: len(train)], sentences[len(train): ]\n",
    "print(len(train_sentences), len(test_sentences))\n",
    "train_idx = np.load(\"../user_data/train_idx.npy\")\n",
    "valid_idx = np.load(\"../user_data/valid_idx.npy\")\n",
    "train_sentences, valid_sentences = [train_sentences[idx] for idx in train_idx], [train_sentences[idx] for idx in valid_idx]\n",
    "train_labels, valid_labels = [labels[idx] for idx in train_idx], [labels[idx] for idx in valid_idx]\n",
    "print(len(train_sentences), len(train_labels))\n",
    "print(len(valid_sentences), len(valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0f63d76-d3e7-4e8f-9623-4d3cbb9920fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"text\": train_sentences,\n",
    "    \"label\": train_labels\n",
    "})\n",
    "valid_dataset = Dataset.from_dict({\n",
    "    \"text\": valid_sentences,\n",
    "    \"label\": valid_labels\n",
    "})\n",
    "test_dataset = Dataset.from_dict({\n",
    "    \"text\": test_sentences\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ebd7621-6650-4b76-9ef6-bba789a8527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "\n",
    "path = \"../user_data/classification_output_0/checkpoint-1500\"\n",
    "model = BertForSequenceClassification.from_pretrained(path)\n",
    "tokenizer = BertTokenizer.from_pretrained(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "847a312b-d20d-4d10-8146-81eec3f67de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc1da168864f44878f1a62e05f4ccba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "083b9df4b84b4eafb85bbe8cb26de20d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a14ec470ce054bd9918516793e985c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess(examples):\n",
    "    \"\"\"单个处理\"\"\"\n",
    "    input_ids, token_type_ids, attention_mask = tokenizer.encode_plus(\n",
    "        examples[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        max_length=1024,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).values()\n",
    "    examples[\"input_ids\"] = input_ids[0]\n",
    "    examples[\"token_type_ids\"] = token_type_ids[0]\n",
    "    examples[\"attention_mask\"] = attention_mask[0]\n",
    "    return examples\n",
    "\n",
    "\n",
    "train_encoded = train_dataset.map(preprocess)\n",
    "valid_encoded = valid_dataset.map(preprocess)\n",
    "test_encoded = test_dataset.map(preprocess)\n",
    "\n",
    "train_encoded.set_format(\"torch\", columns=[\"label\", \"input_ids\", \"token_type_ids\", \"attention_mask\"])\n",
    "valid_encoded.set_format(\"torch\", columns=[\"label\", \"input_ids\", \"token_type_ids\", \"attention_mask\"])\n",
    "test_encoded.set_format(\"torch\", columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2285c11-9ce9-4b75-a6db-22ef31cd14f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1398e81c5f457fa0ccec695f5fe5f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3962ab3300b416cbf803fc3fee01e35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10d5f113c583433c8d89e65d164ce76d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model.to(device)\n",
    "def get_logits(batch):\n",
    "    with torch.no_grad():\n",
    "        input_ids, token_type_ids, attention_mask = batch[\"input_ids\"].to(device), batch[\"token_type_ids\"].to(device), batch[\"attention_mask\"].to(device)\n",
    "        result = model(input_ids=input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n",
    "        batch[\"logits\"] = result.logits\n",
    "        return batch\n",
    "\n",
    "train_encoded = train_encoded.map(get_logits, batched=True, batch_size=64)\n",
    "valid_encoded = valid_encoded.map(get_logits, batched=True, batch_size=64)\n",
    "test_encoded = test_encoded.map(get_logits, batched=True, batch_size=64)\n",
    "\n",
    "train_encoded.set_format(\"torch\", columns=[\"label\", \"input_ids\", \"token_type_ids\", \"attention_mask\", \"logits\"])\n",
    "valid_encoded.set_format(\"torch\", columns=[\"label\", \"input_ids\", \"token_type_ids\", \"attention_mask\", \"logits\"])\n",
    "test_encoded.set_format(\"torch\", columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"logits\"])\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2df49027-0660-49d3-b5fe-3ded500526d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9562f28ae94148c1b888178c40cf60fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/16000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef1d7a73963407787a267029f08ea41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d9b1b3b833b42a1bfa75d51b7a3e7ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/6500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "\n",
    "dataset_for_nsp = DatasetDict({\n",
    "    \"train\": train_encoded,\n",
    "    \"valid\": valid_encoded,\n",
    "    \"test\": test_encoded\n",
    "})\n",
    "dataset_for_nsp.save_to_disk(\"../user_data/dataset_for_nsp\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
